{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n",
      "4.3.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from data import LoadTest\n",
    "from model import VGG16\n",
    "from utils import *\n",
    "\n",
    "for name in (torch, torchvision, cv2, np):\n",
    "    print(name.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TE/DUTS-TE-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TE/DUTS-TE-Mask/\"\n",
    "\n",
    "# path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "# path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "batch_size = 4 #受限于贫穷，4是极限了\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"./model/MPFA_35.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1255 acc:0.9188623428344727 pre:0.8231050968170166 recall:0.8173074722290039 F-measure:0.8171997666358948\n",
      "Batch:200/1255 acc:0.9224636554718018 pre:0.8251875042915344 recall:0.8134044408798218 F-measure:0.8168741464614868\n",
      "Batch:300/1255 acc:0.9210756421089172 pre:0.8215697407722473 recall:0.8126248717308044 F-measure:0.8134785294532776\n",
      "Batch:400/1255 acc:0.9179564714431763 pre:0.8214311599731445 recall:0.814199686050415 F-measure:0.8132904767990112\n",
      "Batch:500/1255 acc:0.916031539440155 pre:0.8279200196266174 recall:0.809859037399292 F-measure:0.8173554539680481\n",
      "Batch:600/1255 acc:0.915207028388977 pre:0.8268163800239563 recall:0.8128423690795898 F-measure:0.8173531889915466\n",
      "Batch:700/1255 acc:0.9173167943954468 pre:0.825914740562439 recall:0.8130220770835876 F-measure:0.8166686296463013\n",
      "Batch:800/1255 acc:0.9145312309265137 pre:0.8289052248001099 recall:0.8091350197792053 F-measure:0.8180011510848999\n",
      "Batch:900/1255 acc:0.9146939516067505 pre:0.8113747239112854 recall:0.7994425892829895 F-measure:0.8018438816070557\n",
      "Batch:1000/1255 acc:0.9151718020439148 pre:0.7972089052200317 recall:0.7903035879135132 F-measure:0.7881504893302917\n",
      "Batch:1100/1255 acc:0.9149829745292664 pre:0.7863995432853699 recall:0.784380316734314 F-measure:0.7780267000198364\n",
      "Batch:1200/1255 acc:0.9159836173057556 pre:0.7797552347183228 recall:0.7810829877853394 F-measure:0.7718270421028137\n",
      "--------------------------------------------------------------\n",
      "time:659.43s END : acc:0.916275143623352 pre:0.7748098373413086 rec:0.7786822319030762 F-measure:0.7668504118919373\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1292 acc:0.9222933650016785 pre:0.7668030261993408 recall:0.735341489315033 F-measure:0.7447482943534851\n",
      "Batch:200/1292 acc:0.9186984300613403 pre:0.7471588253974915 recall:0.7281694412231445 F-measure:0.7299389243125916\n",
      "Batch:300/1292 acc:0.9131788611412048 pre:0.7473057508468628 recall:0.7123088240623474 F-measure:0.7259295582771301\n",
      "Batch:400/1292 acc:0.912373960018158 pre:0.7350950241088867 recall:0.7127103805541992 F-measure:0.714939534664154\n",
      "Batch:500/1292 acc:0.9133810997009277 pre:0.7295538783073425 recall:0.7169082164764404 F-measure:0.711651086807251\n",
      "Batch:600/1292 acc:0.9155968427658081 pre:0.7283015251159668 recall:0.7259585857391357 F-measure:0.7131957411766052\n",
      "Batch:700/1292 acc:0.9161477088928223 pre:0.7293208241462708 recall:0.7245139479637146 F-measure:0.7142395973205566\n",
      "Batch:800/1292 acc:0.9155284762382507 pre:0.73087477684021 recall:0.7243167757987976 F-measure:0.7155505418777466\n",
      "Batch:900/1292 acc:0.9171620011329651 pre:0.7324743270874023 recall:0.73215252161026 F-measure:0.7191596031188965\n",
      "Batch:1000/1292 acc:0.9178453087806702 pre:0.7316932678222656 recall:0.7345540523529053 F-measure:0.7193293571472168\n",
      "Batch:1100/1292 acc:0.9188807606697083 pre:0.7325951457023621 recall:0.7346503138542175 F-measure:0.7199241518974304\n",
      "Batch:1200/1292 acc:0.920120894908905 pre:0.7353926301002502 recall:0.737056314945221 F-measure:0.7226954102516174\n",
      "--------------------------------------------------------------\n",
      "time:681.15s END : acc:0.92020583152771 pre:0.7323538064956665 rec:0.736027181148529 F-measure:0.7200024724006653\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
