{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n",
      "4.3.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from data import LoadTest\n",
    "from model import VGG16\n",
    "from utils import *\n",
    "\n",
    "for name in (torch, torchvision, cv2, np):\n",
    "    print(name.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TE/DUTS-TE-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TE/DUTS-TE-Mask/\"\n",
    "\n",
    "# path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "# path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "batch_size = 4 #受限于贫穷，4是极限了\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"./model/MPFA_23.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1255 acc:0.9206241965293884 pre:0.8311856389045715 recall:0.8233010768890381 F-measure:0.8252055048942566\n",
      "Batch:200/1255 acc:0.9226438403129578 pre:0.8269964456558228 recall:0.8106570243835449 F-measure:0.8178164958953857\n",
      "Batch:300/1255 acc:0.921343207359314 pre:0.8259572386741638 recall:0.8087315559387207 F-measure:0.8157474994659424\n",
      "Batch:400/1255 acc:0.9187116622924805 pre:0.827335774898529 recall:0.8106575608253479 F-measure:0.8172340393066406\n",
      "Batch:500/1255 acc:0.916764497756958 pre:0.8321555852890015 recall:0.8072196841239929 F-measure:0.8203149437904358\n",
      "Batch:600/1255 acc:0.9159462451934814 pre:0.8314943909645081 recall:0.8090721368789673 F-measure:0.8205786943435669\n",
      "Batch:700/1255 acc:0.9180043339729309 pre:0.8312079906463623 recall:0.8081604838371277 F-measure:0.8201680779457092\n",
      "Batch:800/1255 acc:0.9149702191352844 pre:0.8332365155220032 recall:0.8033570647239685 F-measure:0.8203142285346985\n",
      "Batch:900/1255 acc:0.9152230620384216 pre:0.8175768852233887 recall:0.7924737334251404 F-measure:0.8053135275840759\n",
      "Batch:1000/1255 acc:0.9157142639160156 pre:0.8039520382881165 recall:0.7828368544578552 F-measure:0.7916631698608398\n",
      "Batch:1100/1255 acc:0.9158536195755005 pre:0.7948122620582581 recall:0.7759385704994202 F-measure:0.7826278805732727\n",
      "Batch:1200/1255 acc:0.9168406128883362 pre:0.7878686189651489 recall:0.7722684741020203 F-measure:0.7761932015419006\n",
      "--------------------------------------------------------------\n",
      "time:661.36s END : acc:0.9171533584594727 pre:0.7833353281021118 rec:0.7705724835395813 F-measure:0.7716649174690247\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1292 acc:0.9200150966644287 pre:0.7621504664421082 recall:0.711332380771637 F-measure:0.7327218651771545\n",
      "Batch:200/1292 acc:0.9163889288902283 pre:0.74155592918396 recall:0.7027488350868225 F-measure:0.7175220847129822\n",
      "Batch:300/1292 acc:0.9113218188285828 pre:0.7465049028396606 recall:0.6896727681159973 F-measure:0.7169625759124756\n",
      "Batch:400/1292 acc:0.9111647605895996 pre:0.7375941872596741 recall:0.690802812576294 F-measure:0.7092563509941101\n",
      "Batch:500/1292 acc:0.9131141304969788 pre:0.7345632314682007 recall:0.6968173980712891 F-measure:0.7092639207839966\n",
      "Batch:600/1292 acc:0.9157516956329346 pre:0.7354938983917236 recall:0.7067985534667969 F-measure:0.7128739953041077\n",
      "Batch:700/1292 acc:0.9161795377731323 pre:0.7358300089836121 recall:0.7055700421333313 F-measure:0.7136293649673462\n",
      "Batch:800/1292 acc:0.9159947037696838 pre:0.7383900880813599 recall:0.7071083784103394 F-measure:0.7162060141563416\n",
      "Batch:900/1292 acc:0.9176831841468811 pre:0.7403017282485962 recall:0.7160386443138123 F-measure:0.7204964756965637\n",
      "Batch:1000/1292 acc:0.9183183908462524 pre:0.7394788265228271 recall:0.7189671397209167 F-measure:0.7207679748535156\n",
      "Batch:1100/1292 acc:0.9196156859397888 pre:0.7414553165435791 recall:0.7211793661117554 F-measure:0.7229480147361755\n",
      "Batch:1200/1292 acc:0.9208386540412903 pre:0.7443281412124634 recall:0.7229000926017761 F-measure:0.7253466248512268\n",
      "--------------------------------------------------------------\n",
      "time:682.44s END : acc:0.9209941029548645 pre:0.7419213652610779 rec:0.7225293517112732 F-measure:0.723152756690979\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
