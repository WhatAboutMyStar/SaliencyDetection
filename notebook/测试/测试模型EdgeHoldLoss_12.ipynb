{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n",
      "4.3.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from data import LoadTest\n",
    "from model import VGG16\n",
    "from utils import *\n",
    "\n",
    "for name in (torch, torchvision, cv2, np):\n",
    "    print(name.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TE/DUTS-TE-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TE/DUTS-TE-Mask/\"\n",
    "\n",
    "# path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "# path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "batch_size = 4 #受限于贫穷，4是极限了\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"./model/model_63_edge.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1255 acc:0.9211519956588745 pre:0.8363354206085205 recall:0.81751948595047 F-measure:0.826934278011322\n",
      "Batch:200/1255 acc:0.923424482345581 pre:0.836095929145813 recall:0.8067910075187683 F-measure:0.823300838470459\n",
      "Batch:300/1255 acc:0.9222207069396973 pre:0.8344525098800659 recall:0.8035025596618652 F-measure:0.8207411170005798\n",
      "Batch:400/1255 acc:0.919651985168457 pre:0.8366708159446716 recall:0.8026110529899597 F-measure:0.8221774697303772\n",
      "Batch:500/1255 acc:0.9177623391151428 pre:0.8427778482437134 recall:0.7984902262687683 F-measure:0.8259250521659851\n",
      "Batch:600/1255 acc:0.9166973233222961 pre:0.8395371437072754 recall:0.80170738697052 F-measure:0.8244283199310303\n",
      "Batch:700/1255 acc:0.9188193678855896 pre:0.8389427661895752 recall:0.8014369606971741 F-measure:0.8241152167320251\n",
      "Batch:800/1255 acc:0.9159017205238342 pre:0.8419498801231384 recall:0.7975098490715027 F-measure:0.8251850605010986\n",
      "Batch:900/1255 acc:0.9162983894348145 pre:0.8266974091529846 recall:0.7865564227104187 F-measure:0.8104361295700073\n",
      "Batch:1000/1255 acc:0.916760265827179 pre:0.8140495419502258 recall:0.7759782671928406 F-measure:0.7972643375396729\n",
      "Batch:1100/1255 acc:0.9169600009918213 pre:0.8047849535942078 recall:0.7698866128921509 F-measure:0.7883645296096802\n",
      "Batch:1200/1255 acc:0.9181027412414551 pre:0.7982709407806396 recall:0.7679852247238159 F-measure:0.7828479409217834\n",
      "--------------------------------------------------------------\n",
      "time:649.75s END : acc:0.918442964553833 pre:0.7934461236000061 rec:0.7669548988342285 F-measure:0.7784876823425293\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1292 acc:0.9244320392608643 pre:0.7868181467056274 recall:0.7281914949417114 F-measure:0.7548874616622925\n",
      "Batch:200/1292 acc:0.9214763641357422 pre:0.7689417600631714 recall:0.7267668843269348 F-measure:0.7445794343948364\n",
      "Batch:300/1292 acc:0.9168199896812439 pre:0.7704431414604187 recall:0.7177650332450867 F-measure:0.7434800863265991\n",
      "Batch:400/1292 acc:0.917252779006958 pre:0.7615127563476562 recall:0.7205209136009216 F-measure:0.7380211353302002\n",
      "Batch:500/1292 acc:0.9190511107444763 pre:0.760217010974884 recall:0.726555347442627 F-measure:0.7383942008018494\n",
      "Batch:600/1292 acc:0.9208983778953552 pre:0.7570948004722595 recall:0.7338256239891052 F-measure:0.7382784485816956\n",
      "Batch:700/1292 acc:0.9210798144340515 pre:0.7558550834655762 recall:0.7313951849937439 F-measure:0.7373591065406799\n",
      "Batch:800/1292 acc:0.9207730889320374 pre:0.7566506266593933 recall:0.7336471676826477 F-measure:0.738972008228302\n",
      "Batch:900/1292 acc:0.9221975207328796 pre:0.7581236362457275 recall:0.7417520880699158 F-measure:0.7425500154495239\n",
      "Batch:1000/1292 acc:0.9227568507194519 pre:0.7577695250511169 recall:0.7442806959152222 F-measure:0.7429598569869995\n",
      "Batch:1100/1292 acc:0.9237884879112244 pre:0.758059024810791 recall:0.7457665801048279 F-measure:0.7435610890388489\n",
      "Batch:1200/1292 acc:0.9249672889709473 pre:0.7611265778541565 recall:0.7482317686080933 F-measure:0.7465766072273254\n",
      "--------------------------------------------------------------\n",
      "time:667.82s END : acc:0.9250003099441528 pre:0.7583761811256409 rec:0.7466148138046265 F-measure:0.7439153790473938\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
