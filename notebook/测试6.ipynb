{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n",
      "4.3.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from data import LoadTest\n",
    "from model import VGG16\n",
    "from utils import *\n",
    "\n",
    "for name in (torch, torchvision, cv2, np):\n",
    "    print(name.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TE/DUTS-TE-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TE/DUTS-TE-Mask/\"\n",
    "\n",
    "# path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "# path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "batch_size = 4 #受限于贫穷，4是极限了\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"./model/MPFA_51.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1255 acc:0.9191281199455261 pre:0.816030740737915 recall:0.8355982303619385 F-measure:0.8160198926925659\n",
      "Batch:200/1255 acc:0.9224180579185486 pre:0.8213722705841064 recall:0.8251014351844788 F-measure:0.8167349100112915\n",
      "Batch:300/1255 acc:0.9209890961647034 pre:0.8190389275550842 recall:0.8223370909690857 F-measure:0.8137248158454895\n",
      "Batch:400/1255 acc:0.9185909032821655 pre:0.8223724961280823 recall:0.8223307728767395 F-measure:0.8162429332733154\n",
      "Batch:500/1255 acc:0.9169034957885742 pre:0.8293876647949219 recall:0.819004476070404 F-measure:0.8211193680763245\n",
      "Batch:600/1255 acc:0.9159166812896729 pre:0.8277755379676819 recall:0.8209471106529236 F-measure:0.8203755617141724\n",
      "Batch:700/1255 acc:0.9181726574897766 pre:0.8279935717582703 recall:0.8210899233818054 F-measure:0.8207377195358276\n",
      "Batch:800/1255 acc:0.9154171347618103 pre:0.8316827416419983 recall:0.8164752125740051 F-measure:0.8222788572311401\n",
      "Batch:900/1255 acc:0.9157974123954773 pre:0.815994918346405 recall:0.8048646450042725 F-measure:0.8072112798690796\n",
      "Batch:1000/1255 acc:0.9160110354423523 pre:0.8010475039482117 recall:0.7954423427581787 F-measure:0.792687714099884\n",
      "Batch:1100/1255 acc:0.9158813953399658 pre:0.790187656879425 recall:0.7878418564796448 F-measure:0.7822200655937195\n",
      "Batch:1200/1255 acc:0.9167812466621399 pre:0.7827303409576416 recall:0.783738911151886 F-measure:0.7753498554229736\n",
      "--------------------------------------------------------------\n",
      "time:657.69s END : acc:0.9170575737953186 pre:0.7775589823722839 rec:0.782244086265564 F-measure:0.7705432176589966\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1292 acc:0.9205004572868347 pre:0.7606207728385925 recall:0.7369702458381653 F-measure:0.7387913465499878\n",
      "Batch:200/1292 acc:0.9172635674476624 pre:0.7403751015663147 recall:0.7279025316238403 F-measure:0.7247220277786255\n",
      "Batch:300/1292 acc:0.9117786884307861 pre:0.7394692897796631 recall:0.7124938368797302 F-measure:0.7195568680763245\n",
      "Batch:400/1292 acc:0.9118021726608276 pre:0.7313506007194519 recall:0.7132731676101685 F-measure:0.7123115658760071\n",
      "Batch:500/1292 acc:0.9135990738868713 pre:0.7298102378845215 recall:0.7164260745048523 F-measure:0.7121318578720093\n",
      "Batch:600/1292 acc:0.9155578017234802 pre:0.7266045808792114 recall:0.7236361503601074 F-measure:0.7118256092071533\n",
      "Batch:700/1292 acc:0.9161108136177063 pre:0.7272526621818542 recall:0.7215961217880249 F-measure:0.7125101685523987\n",
      "Batch:800/1292 acc:0.9157483577728271 pre:0.7295728325843811 recall:0.7221245169639587 F-measure:0.7138474583625793\n",
      "Batch:900/1292 acc:0.9173011779785156 pre:0.731046199798584 recall:0.7303820848464966 F-measure:0.7173495888710022\n",
      "Batch:1000/1292 acc:0.9180980920791626 pre:0.7312567234039307 recall:0.7332469820976257 F-measure:0.7184262871742249\n",
      "Batch:1100/1292 acc:0.919277548789978 pre:0.7324186563491821 recall:0.7346847653388977 F-measure:0.7195719480514526\n",
      "Batch:1200/1292 acc:0.9206416010856628 pre:0.7359573841094971 recall:0.736918032169342 F-measure:0.7228444814682007\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
