{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0+cu101'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from data import LoadData\n",
    "from model import VGG16\n",
    "from torch.utils import data\n",
    "from utils import *\n",
    "from loss import EdgeSaliencyLoss\n",
    "import os\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TR/DUTS-TR-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TR/DUTS-TR-Mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10553"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(path_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 1e-3\n",
    "target_size = 256\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2638"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(os.listdir(path_image)) // batch_size\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadData(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['mfe1.conv11.weight', 'mfe1.conv11.bias', 'mfe1.conv33.weight', 'mfe1.conv33.bias', 'mfe1.conv55.weight', 'mfe1.conv55.bias', 'mfe2.conv11.weight', 'mfe2.conv11.bias', 'mfe2.conv33.weight', 'mfe2.conv33.bias', 'mfe2.conv55.weight', 'mfe2.conv55.bias', 'mfe3.conv11.weight', 'mfe3.conv11.bias', 'mfe3.conv33.weight', 'mfe3.conv33.bias', 'mfe3.conv55.weight', 'mfe3.conv55.bias', 'mfe4.conv11.weight', 'mfe4.conv11.bias', 'mfe4.conv33.weight', 'mfe4.conv33.bias', 'mfe4.conv55.weight', 'mfe4.conv55.bias', 'mfe5.conv11.weight', 'mfe5.conv11.bias', 'mfe5.conv33.weight', 'mfe5.conv33.bias', 'mfe5.conv55.weight', 'mfe5.conv55.bias', 'mfe6.conv11.weight', 'mfe6.conv11.bias', 'mfe6.conv33.weight', 'mfe6.conv33.bias', 'mfe6.conv55.weight', 'mfe6.conv55.bias', 'mfe7.conv11.weight', 'mfe7.conv11.bias', 'mfe7.conv33.weight', 'mfe7.conv33.bias', 'mfe7.conv55.weight', 'mfe7.conv55.bias', 'mfe8.conv11.weight', 'mfe8.conv11.bias', 'mfe8.conv33.weight', 'mfe8.conv33.bias', 'mfe8.conv55.weight', 'mfe8.conv55.bias', 'mfe11.conv11.weight', 'mfe11.conv11.bias', 'mfe11.conv33.weight', 'mfe11.conv33.bias', 'mfe11.conv55.weight', 'mfe11.conv55.bias', 'mfe12.conv11.weight', 'mfe12.conv11.bias', 'mfe12.conv33.weight', 'mfe12.conv33.bias', 'mfe12.conv55.weight', 'mfe12.conv55.bias', 'CA.linear_1.weight', 'CA.linear_1.bias', 'CA.linear_2.weight', 'CA.linear_2.bias', 'SA.conv1k_1.weight', 'SA.conv1k_1.bias', 'SA.bn1_1.weight', 'SA.bn1_1.bias', 'SA.bn1_1.running_mean', 'SA.bn1_1.running_var', 'SA.convk1_1.weight', 'SA.convk1_1.bias', 'SA.bn2_1.weight', 'SA.bn2_1.bias', 'SA.bn2_1.running_mean', 'SA.bn2_1.running_var', 'SA.convk1_2.weight', 'SA.convk1_2.bias', 'SA.bn1_2.weight', 'SA.bn1_2.bias', 'SA.bn1_2.running_mean', 'SA.bn1_2.running_var', 'SA.conv1k_2.weight', 'SA.conv1k_2.bias', 'SA.bn2_2.weight', 'SA.bn2_2.bias', 'SA.bn2_2.running_mean', 'SA.bn2_2.running_var', 'conv11.weight', 'conv11.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn4.weight', 'bn4.bias', 'bn4.running_mean', 'bn4.running_var', 'conv.weight', 'conv.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model/vgg16_no_top.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = EdgeSaliencyLoss(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpooling1): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpooling2): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpooling3): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpooling4): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpooling5): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (mfe1): MFE(\n",
       "    (conv11): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe2): MFE(\n",
       "    (conv11): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(1024, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe3): MFE(\n",
       "    (conv11): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(512, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe4): MFE(\n",
       "    (conv11): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe5): MFE(\n",
       "    (conv11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe6): MFE(\n",
       "    (conv11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe7): MFE(\n",
       "    (conv11): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe8): MFE(\n",
       "    (conv11): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe11): MFE(\n",
       "    (conv11): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(192, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (mfe12): MFE(\n",
       "    (conv11): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv33): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv55): Conv2d(768, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (CA): ChannelWiseAttention(\n",
       "    (linear_1): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (linear_2): Linear(in_features=128, out_features=512, bias=True)\n",
       "  )\n",
       "  (SA): SpatialAttention(\n",
       "    (conv1k_1): Conv2d(64, 32, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
       "    (bn1_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convk1_1): Conv2d(32, 1, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
       "    (bn2_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convk1_2): Conv2d(64, 32, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
       "    (bn1_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1k_2): Conv2d(32, 1, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
       "    (bn2_2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv11): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.44 GiB already allocated; 844.80 KiB free; 4.52 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-fde65e626d47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\GitHub\\毕业设计\\MyModel\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# S A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                 \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m                 \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\GitHub\\毕业设计\\MyModel\\attention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mfeatures_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvk1_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mfeatures_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mfeatures_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m#Group2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.44 GiB already allocated; 844.80 KiB free; 4.52 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(image)\n",
    "        loss = criterion(predict, mask)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_n % 100 == 0:\n",
    "            acc = accuracy(predict, mask)\n",
    "            pre = precision(predict, mask)\n",
    "            rec = recall(predict, mask)\n",
    "            f_score = (1 + 0.3) * pre * rec / (0.3 * pre + rec)\n",
    "            print(\"Epoch:{} loss:{} Batch:{}/{}\".format(epoch + 1, loss.item(), batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\".format(acc, pre, rec, f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"./model/model_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_resize_image(inp_img, out_img=None, target_size=None):\n",
    "    h, w, c = inp_img.shape\n",
    "    size = max(h, w)\n",
    "\n",
    "    padding_h = (size - h) // 2\n",
    "    padding_w = (size - w) // 2\n",
    "\n",
    "    if out_img is None:\n",
    "        # For inference\n",
    "        temp_x = cv2.copyMakeBorder(inp_img, top=padding_h, bottom=padding_h, left=padding_w, right=padding_w,\n",
    "                                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        if target_size is not None:\n",
    "            temp_x = cv2.resize(temp_x, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "        return temp_x\n",
    "    else:\n",
    "        # For training and testing\n",
    "        temp_x = cv2.copyMakeBorder(inp_img, top=padding_h, bottom=padding_h, left=padding_w, right=padding_w,\n",
    "                                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        temp_y = cv2.copyMakeBorder(out_img, top=padding_h, bottom=padding_h, left=padding_w, right=padding_w,\n",
    "                                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        # print(inp_img.shape, temp_x.shape, out_img.shape, temp_y.shape)\n",
    "\n",
    "        if target_size is not None:\n",
    "            temp_x = cv2.resize(temp_x, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "            temp_y = cv2.resize(temp_y, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "        return temp_x, temp_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInput(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype('float32')\n",
    "    \n",
    "    img = pad_resize_image(img, target_size=256)\n",
    "    img /= 255.\n",
    "    img = np.transpose(img, axes=(2, 0, 1))\n",
    "    img = torch.from_numpy(img).float()\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225]) \n",
    "    \n",
    "    img = normalize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = getInput(\"./image/1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(1, 3, 256, 256)\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = predict.reshape(256, 256, 1)\n",
    "msk = msk.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"test\", np.array(msk))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
