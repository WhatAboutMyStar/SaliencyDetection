{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n",
      "4.3.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from data import LoadTest\n",
    "from model import VGG16\n",
    "from utils import *\n",
    "\n",
    "for name in (torch, torchvision, cv2, np):\n",
    "    print(name.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUTS/DUTS-TE/DUTS-TE-Image/\"\n",
    "path_mask = \"./DUTS/DUTS-TE/DUTS-TE-Mask/\"\n",
    "\n",
    "# path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "# path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "batch_size = 4 #受限于贫穷，4是极限了\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"./model/MPFA_13.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1255 acc:0.9154441356658936 pre:0.7836655974388123 recall:0.8492724299430847 F-measure:0.7935712933540344\n",
      "Batch:200/1255 acc:0.9193875789642334 pre:0.7886249423027039 recall:0.841928243637085 F-measure:0.7950478792190552\n",
      "Batch:300/1255 acc:0.9183208346366882 pre:0.7895850539207458 recall:0.8377615809440613 F-measure:0.7943596839904785\n",
      "Batch:400/1255 acc:0.9156412482261658 pre:0.7915717959403992 recall:0.8377980589866638 F-measure:0.7958022952079773\n",
      "Batch:500/1255 acc:0.9141197204589844 pre:0.7993139624595642 recall:0.8347060680389404 F-measure:0.8014042377471924\n",
      "Batch:600/1255 acc:0.9131703972816467 pre:0.7982932329177856 recall:0.8358916640281677 F-measure:0.8010583519935608\n",
      "Batch:700/1255 acc:0.9155195951461792 pre:0.7998061776161194 recall:0.8348545432090759 F-measure:0.8020560145378113\n",
      "Batch:800/1255 acc:0.9127400517463684 pre:0.8033658266067505 recall:0.8305174708366394 F-measure:0.8036215305328369\n",
      "Batch:900/1255 acc:0.9129847288131714 pre:0.7876274585723877 recall:0.8200954794883728 F-measure:0.7885144948959351\n",
      "Batch:1000/1255 acc:0.91358482837677 pre:0.7752876281738281 recall:0.8107466697692871 F-measure:0.7760903239250183\n",
      "Batch:1100/1255 acc:0.9133463501930237 pre:0.7645587921142578 recall:0.8040791153907776 F-measure:0.7656729817390442\n",
      "Batch:1200/1255 acc:0.9143021702766418 pre:0.7583999037742615 recall:0.8004968762397766 F-measure:0.7596997022628784\n",
      "--------------------------------------------------------------\n",
      "time:660.51s END : acc:0.914382815361023 pre:0.7524176239967346 rec:0.7983973622322083 F-measure:0.7539439797401428\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = \"./DUT-OMROM/DUT-OMRON-image/\"\n",
    "path_mask = \"./DUT-OMROM/pixelwiseGT-new-PNG/\"\n",
    "\n",
    "data_loader = data.DataLoader(LoadTest(path_image, path_mask, target_size),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100/1292 acc:0.9160940051078796 pre:0.7323072552680969 recall:0.7230894565582275 F-measure:0.7116811871528625\n",
      "Batch:200/1292 acc:0.9132612347602844 pre:0.7174451351165771 recall:0.7206259965896606 F-measure:0.7038479447364807\n",
      "Batch:300/1292 acc:0.9087569117546082 pre:0.7217282056808472 recall:0.7097184062004089 F-measure:0.7049781680107117\n",
      "Batch:400/1292 acc:0.9084843397140503 pre:0.7107465267181396 recall:0.7113921046257019 F-measure:0.696537971496582\n",
      "Batch:500/1292 acc:0.9107286930084229 pre:0.7118368148803711 recall:0.7182673811912537 F-measure:0.6987098455429077\n",
      "Batch:600/1292 acc:0.9128850698471069 pre:0.7112278938293457 recall:0.728011429309845 F-measure:0.7004060745239258\n",
      "Batch:700/1292 acc:0.9133540391921997 pre:0.7113133668899536 recall:0.7263215184211731 F-measure:0.7007025480270386\n",
      "Batch:800/1292 acc:0.9130309224128723 pre:0.7133192420005798 recall:0.7270708084106445 F-measure:0.7026651501655579\n",
      "Batch:900/1292 acc:0.9146514534950256 pre:0.7148489952087402 recall:0.7355523705482483 F-measure:0.7062284350395203\n",
      "Batch:1000/1292 acc:0.9152916073799133 pre:0.7147436141967773 recall:0.7381213903427124 F-measure:0.7070395350456238\n",
      "Batch:1100/1292 acc:0.916299045085907 pre:0.7140963077545166 recall:0.7395697236061096 F-measure:0.7071393132209778\n",
      "Batch:1200/1292 acc:0.9175003170967102 pre:0.7155895233154297 recall:0.741402268409729 F-measure:0.7086907625198364\n",
      "--------------------------------------------------------------\n",
      "time:681.55s END : acc:0.9175728559494019 pre:0.7128497362136841 rec:0.7413416504859924 F-measure:0.7064721584320068\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f_score = 0\n",
    "\n",
    "for batch_n, (image, mask) in enumerate(data_loader, start=1):\n",
    "\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    predict = model(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = accuracy(predict, mask)\n",
    "        total_acc += acc\n",
    "\n",
    "        pre = precision(predict, mask)\n",
    "        total_pre += pre\n",
    "\n",
    "        rec = recall(predict, mask)\n",
    "        total_rec += rec\n",
    "\n",
    "        f_score = F_Measure(pre, rec)\n",
    "        total_f_score += f_score\n",
    "\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_acc = total_acc / batch_n\n",
    "            avg_pre = total_pre / batch_n\n",
    "            avg_rec = total_rec / batch_n\n",
    "            avg_f_score = total_f_score / batch_n\n",
    "            print(\"Batch:{}/{}\".format( batch_n, total_batch), end=\"\")\n",
    "            print(\" acc:{} pre:{} recall:{} F-measure:{}\"\n",
    "                  .format(avg_acc, avg_pre, avg_rec, avg_f_score))\n",
    "end_time = time.time()\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"time:{:.2f}s END : acc:{} pre:{} rec:{} F-measure:{}\"\n",
    "      .format(end_time - start_time, \n",
    "              total_acc / total_batch,\n",
    "              total_pre / total_batch,\n",
    "              total_rec / total_batch,\n",
    "              total_f_score / total_batch))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
